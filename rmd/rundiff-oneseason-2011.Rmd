---
title: "Evaluation of a simple single-year team ability model"
---

```{r setup, include = FALSE}
source("setup.R")

library(dplyr)
library(forcats)
library(ggplot2)
library(readr)
library(stringr)
library(tidyr)

library(rstan)
library(bayesplot)

source("plot-utils.R")

color_scheme_set(c("green"))
theme_set(theme_minimal())
theme_setup()

source("../lib/utils.R")
```

## Single-year estimation of team ability

Eventually I want to estimate the association between a team having
jet lag and some measure of their tendency to win a game.  As a
starting point, I remembered that Andrew Gelman
had [some][p1] [posts][p2] on estimating the ability of teams in the
World Cup teams.  The response in that model is the score
differential: goals in that case, runs my case.  As Gelman discusses,
this isn't a generative model because it makes continuous predictions
for discrete data, but it may be good enough for my purposes.

[p1]: http://andrewgelman.com/2014/07/13/stan-analyzes-world-cup-data/
[p2]: http://andrewgelman.com/2014/07/15/stan-world-cup-update/

Below is a model that closely follows the World Cup model.

```{r, cache.extra = tools::md5sum("../models/rundiff-oneseason.stan"), echo = FALSE, comment = NA, collapse = FALSE}
writeLines(readLines("../models/rundiff-oneseason.stan"))
```

There are two main differences from the World Cup model:

  * I haven't yet bothered to put the response (difference in runs) on
    the square-root scale.

  * I don't include a prior estimate for a team's ability.

And while I'm labeling one team as "home" and one as "away", the model
isn't treating them any differently (e.g., I haven't yet tried to add
a parameter for home-field advantage).

## MCMC diagnostics

I've fit this model using data for the 2011 season.  I'll look at a
few diagnostic plots using the [bayesplot] package.

[bayesplot]: http://mc-stan.org/users/interfaces/bayesplot.html

```{r fit, cache.extra = tools::md5sum("../models/rundiff-oneseason_2011-fit.rds")}
fit <- readRDS("../models/rundiff-oneseason_2011-fit.rds")
```

The R-hats and effective sample sizes look OK, though the effective
sample size for $\sigma_a$ is relatively low.

```{r selpars, dependson = "fit"}
selpars <- c("sigma_a", "sigma_y", grep("^a", names(fit), value = TRUE))
```

```{r nr_plot, dependson = c("fit", "selpars"), out.width = "50%", fig.width = 4.28, fig.align = "default"}
mcmc_neff(neff_ratio(fit, pars = selpars)) +
    theme(panel.grid = element_blank(),
          legend.position = "left")

mcmc_rhat(rhat(fit, pars = selpars)) +
    legend_text(hjust = 0) +
    theme(panel.grid = element_blank(),
          legend.text.align = 0)
```

```{r samps_flat, dependson = "fit"}
samps_flat <- as.array(fit)
```

The autocorrelation across iterations looks OK.  As expected from its
lower effective sample size ratio, $\sigma_a$ shows a higher
autocorrelation than other parameters do.

```{r, include = FALSE}
color_scheme_set("darkgray")
```

```{r acf_plot_sigma, dependson = "samps_flat"}
mcmc_acf(samps_flat, regex_pars = "sigma") +
    theme(panel.grid = element_blank())
```

```{r acf_plot_a, dependson = "samps_flat", out.width = "95%", fig.width = 8.14}
mcmc_acf(samps_flat, pars = paste0("a[", 1:6, "]")) +
    theme(panel.grid = element_blank())
```

The traces look OK.

```{r sigma_trace_plots, dependson = "samps_flat", fig.asp = 0.35}
color_scheme_set("mix-darkgray-green")
mcmc_trace(samps_flat, regex_pars = "sigma") +
    theme_axis_line()
```

```{r sigma_a_plots, dependson = "samps_flat", out.width = "95%", fig.width = 8.14, fig.asp = 0.75}
mcmc_trace(samps_flat, regex_pars = "^a\\[", facet_args = list(ncol = 5)) +
    theme(legend.position = "none",
          axis.text.x = element_blank()) +
    theme_axis_line()
```

## Ability estimates

The order of team ability estimates should largely follow the final
rankings for the 2011 season.

```{r glog, cache.extra = tools::md5sum("lag/log-with-lags-cleaned.csv")}
glog <- read_csv("../lag/log-with-lags-cleaned.csv")
```

```{r team_rank, dependson = "glog"}
(team_rank <- glog %>%
     filter(lubridate::year(date) == 2011) %>%
     count_wins() %>%
     mutate(win_perc = n_wins / n_games) %>%
     arrange(desc(win_perc)))

team_names <- levels(factor(team_rank$team))
```

To get the samples in a more convenient form, I'll re-extract the
samples from the fit as a list rather than an array with flattened
variables name.

```{r samps, dependson = "fit"}
samps <- rstan::extract(fit)
```

```{r avals, dependson = c("samps", "team_rank")}
avals <- trace_intervals(samps$a, "team_idx") %>%
    mutate(team = factor(team_names[team_idx], levels = team_rank$team))
```

```{r avals_plot, dependson = "avals", out.width = "50%", fig.width = 4.28, fig.asp = 1.2}
ggplot(avals, aes(x = fct_rev(team))) +
    geom_hline(yintercept = 0, color = tc$background_light, size = 1) +
    geom_pointrange(aes(y = mean, ymin = p10, ymax = p90)) +
    geom_linerange(aes(ymin = p25, ymax = p75), size = 0.9) +
    labs(x = NULL,
         y = "mean ability (with 50% and 80% intervals)",
         title = "Team ability estimates for 2011 season",
         subtitle = "sorted by regular season standings") +
    coord_flip() +
    theme(panel.grid = element_blank())
```

The intervals are wide and largely overlapping, but the ability
estimates seem to approximately track the season standings.  I don't
expect a one-to-one mapping here because the overall win percentages
don't account for actual match-ups or run differentials.

## Posterior predictive check

To generate new responses from the estimated parameters, I'll pick a
few teams to form the match-ups.  The first three are the teams with
the best 2011 records, the last three are the ones with the worst
records, and the middle teams are somewhere in between.

```{r matchups, dependson = c("team_rank")}
ppc_team_names <- c("PHI", "NYA", "MIL", "ARI", "CIN", "OAK", "PIT",
                    "SEA", "MIN", "HOU")
ppc_teams <- match(ppc_team_names, team_names)

matchups <- data.frame(t(utils::combn(ppc_teams, 2)))
names(matchups) <- c("home", "away")
matchups$home_name <- team_names[matchups$home]
matchups$away_name <- team_names[matchups$away]
```

For each of these match-ups, I'll generate a score differential from
samples for each iteration and then summarize the response across the
iterations by constructing the 95% intervals for each match-up.

```{r rundiff_sim, dependson = c("matchups", "samps")}
df <- 7

n_games <- nrow(matchups)
n_iter <- nrow(samps$sigma_y)
rundiff_sim <- array(NA, c(n_iter, n_games))
set.seed(16125)
for (i in 1:n_iter){
    rundiff_sim[i,] <- samps$a[i, matchups$home] - samps$a[i, matchups$away] +
         rt(n_games, df) * samps$sigma_y[i]
}

result <- cbind(matchups, trace_intervals(rundiff_sim, "game_idx"))  %>%
    as_tibble() %>%
    mutate(matchup = paste(home_name, "-", away_name),
           matchup = factor(matchup, levels = matchup))
```

I also have to pull together the observed run differentials for these
match-ups.  This requires a little bit of work because the simulations
put the team with the better record as the "home" team.

```{r observed, dependson = c("team_names", "rundiff_sim", "result")}
observed <- glog %>%
    filter(lubridate::year(date) == 2011,
           home_team %in% team_names,
           away_team %in% team_names) %>%
    select(home_team, away_team, home_runs_scored, away_runs_scored) %>%
    mutate(flip = match(home_team, team_names) > match(away_team, team_names),
           matchup = ifelse(flip,
                            paste(away_team, "-", home_team),
                            paste(home_team, "-", away_team)),
           matchup = factor(matchup, levels = levels(result$matchup)),
           rundiff = ifelse(flip,
                              away_runs_scored - home_runs_scored,
                              home_runs_scored - away_runs_scored)) %>%
    filter(!is.na(matchup))
```

Now, we can overlay the observed run differentials over the prediction
intervals.  The intervals aren't shown if the match-up didn't occur
during the 2011 season.

```{r ppc_plot, dependson = c("observed")}
result %>%
    filter(matchup %in% observed$matchup) %>%
    ggplot() +
    geom_hline(yintercept = 0, color = tc$primary_lighter) +
    geom_linerange(aes(x = fct_rev(matchup), ymin = p2.5, ymax = p97.5),
                   alpha = 0.8) +
    geom_point(aes(x = matchup, y = rundiff),
               fill = NA, color = tc$background_dark, shape = 21,
               data = observed) +
    scale_y_continuous(limits = c(-13, 13),
                       minor_breaks = -13:13) +
    coord_flip() +
    labs(title = "Run differential",
         subtitle = "compared to the match-up's 95% predictive interval") +
    theme(axis.title.y = element_blank(),
          axis.title.x = element_blank(),
          panel.grid.major.y = element_blank(),
          axis.text.y = element_text(hjust = 0))
```

Well, that seems OK in the sense that 115 of the 122 points (close to
95%) fall within the intervals.

Is this model useful going forward?  I don't know.  If making
predictions from this model were the goal, the intervals are
unhelpfully large. ("Oh, that team's likely to win by 9 or lose by 7?
You don't say.")  And these wide intervals are unsurprising given that
the response is based on a single-season ability estimate for each
team.

Instead, my goal is to find a relatively interpretable model that I
can extend to estimate the association of jet lag with a team's
success in a game.  In that case, the uncertainty of the team-to-team
match-up seems like a good thing to build on.

In order to do that, here are the next steps I'm considering:

  * Introduce terms for different lag effects.

  * Extend the model to handle multiple years.

  * Add a term for a home-team effect.

  * See how the model looks when run differential is put on the
    square-root scale.

  * Break up the ability estimates across the season, similar to Milad
    Kharratzadeh's model of [goal][mk1] [differentials][mk2] in the
    English Premier League.

[mk1]: http://andrewgelman.com/2017/05/17/using-stan-week-week-updating-estimated-soccer-team-abilites/
[mk2]: https://github.com/milkha/EPL

```{r session_info, echo = FALSE, results = "asis"}
source("session-info.R")
```
