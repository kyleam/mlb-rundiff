---
title: "Jet lag calculation checks"
---

```{r setup, include = FALSE}
source("setup.R")

library(dplyr)
library(forcats)
library(ggplot2)
library(lubridate)
library(readr)
library(stringr)
library(tidyr)

source("plot-utils.R")

theme_set(theme_minimal())
theme_setup()
```

Song, Severini, and Allada ("SSA") [estimated the jet lag] of teams
using [Retrosheet] game logs for MLB games from 1992 through 2011.
Starting from the game logs and working from their criteria, I've
attempted to generate the same jet lag data set.  To convince myself
that I've more or less done so, I'll (1) make a few summary plots to
see if things look reasonable and (2) crosscheck my overall numbers
with the information available in SSA's supplemental tables.

[estimated the jet lag]: http://dx.doi.org/10.1073/pnas.1608847114
[Retrosheet]: http://www.retrosheet.org/gamelogs/index.html

## A few sanity checks

### Distribution of games across teams each season

The file "lag-combined-1990_2016.csv" should represent every game
between 1990 and 2016 with two lines, one for each team.  I'll filter
to 1992 through 2011 to match the year range used by SSA.

```{r lag, cache.extra = file.info("../lag/lag-combined-1990_2016.csv")}
(lag <- read_csv("../lag/lag-combined-1990_2016.csv") %>%
     mutate(date = ymd(date),
            year = year(date)) %>%
     filter(between(year, 1992, 2011)) %>%
     mutate(game_tz = factor(game_tz,
                             levels = c("ET", "CT", "MT", "PT", "other"))))
```

Let's tally the number games per team in each season.

```{r game_plot, dependson = "lag", fig.asp = 0.8}
lag %>%
    group_by(year, team) %>%
    summarise(games = n()) %>%
    mutate(normal_season = abs(games - 162) < 4) %>%
    ggplot(aes(year, fct_rev(team))) +
    geom_point(aes(color = normal_season, size = games), shape = 21) +
    ylab(NULL) +
    scale_size(range = c(1, 3.5)) +
    scale_color_manual(values = c("black", "gray60"), guide = FALSE) +
    theme(panel.grid = element_blank())
```

Nothing looks off here after accounting for a few historical events.
Most years are within 3 games of 162 (gray), with the exception of the
1994 and 1995 seasons.  A [strike] disrupted play during these two
years.  In addition to the 1994 and 1995 columns, the other thing that
stands out in the plot above is the presence of incomplete rows.  Some
of these represent births (ARI, COL, FLO, TBA), while the remaining
ones can be paired together to reveal reincarnations (CAL &#8594; ANA,
MON &#8594; WAS).

[strike]: https://en.wikipedia.org/wiki/1994%E2%80%9395_Major_League_Baseball_strike

### Do the lag values look reasonable?

The values of interest in this data set are the lag values.  To make
it easier to visualize these, I'm going to look at the lags of four
teams---one for each time zone---in a single season.

```{r lag2011, dependson = "lag"}
selteams <- c("NYA", "SLN", "COL", "SEA")

lag2011 <- lag  %>%
    filter(year == "2011", team %in% selteams) %>%
    mutate(team = factor(team, levels = selteams))
```

Here are the lags for these teams across the 2011 season.

```{r lag-plot, dependson = "lag2011", out.width = "95%", fig.width = 8.14}
lag2011 %>%
    ggplot(aes(date, lag)) +
    geom_hline(yintercept = 0, color = tc$background_light, size = 1.25) +
    geom_line(alpha = 0.6) +
    geom_point(size = 0.7) +
    scale_x_date(date_breaks = "1 month", date_labels = "%b") +
    scale_y_continuous(breaks = -3:3, limits = c(-3, 3)) +
    theme(panel.grid.minor.y = element_blank(),
          panel.grid.major.y = element_blank(),
          panel.grid.minor.x = element_blank()) +
    facet_wrap(~ team, ncol = 1)
```

This looks like I'd expect:

  * A team spends most of their time at a lag of zero.

  * A lag never goes over a magnitude of three, which is good since
    that should be impossible because ET is coded as 0 and PT at the
    other end is coded as 3.

  * Lags decrease by one with consecutive games.

To assess the time zone shifts in more detail, we can color the points
by time zone and add a grid to more clearly mark individual days.

```{r lag-plot-color, dependson = "lag2011", out.width = "95%", fig.width = 8.14}
colors <- c("#00688b", "#8b0000", "#9400d3", "#2e8b57")

## Create data frame for labeling facets.
zones <- tibble(date = rep(ymd("20110401"), 4),
                lag = rep(2.3, 4),
                team = fct_inorder(levels(lag2011$team)),
                game_tz = levels(droplevels(lag2011$game_tz)),
                label = game_tz)

lag2011 %>%
    ggplot(aes(date, lag)) +
    geom_line(alpha = 0.6) +
    geom_point(aes(color = game_tz), size = 0.7) +
    geom_label(data = zones, aes(label = label, color = game_tz),
               size = 3, hjust = "right") +
    scale_x_date(date_breaks = "1 month",
                 date_minor_breaks = "1 day",
                 date_labels = "%b") +
    scale_y_continuous(breaks = -3:3, limits = c(-3, 3)) +
    scale_color_manual(values = colors) +
    theme(panel.grid.minor.y = element_blank(),
          legend.position = "none") +
    facet_wrap(~ team, ncol = 1)
```

Again, this looks reasonable.  All the time zone shifts seem to match
expectations based on the time zone transitions and the number of off
days.

One shift that seems suspicious is the last upward peak in Seattle's
schedule: the +3 peak is caused by a move the eastern time, but then
Seattle's very next game is in central time.  But, indeed, it looks
like Seattle played [game number 153] against Cleveland and the next
day faced off against the Twins in Minnesota.

[game number 153]: https://www.baseball-reference.com/teams/SEA/2011-schedule-scores.shtml

## Comparison with SSA's tables

As far as I can tell, SSA did not publish their day-by-day lag
calculations or the code they used to generate these.  Using their two
supplemental tables, however, I can gain some idea of whether my
generated data set matches up.

### SSA's Table S1

Here's their Table S1:

```{r, echo = FALSE, results = "asis", cache = FALSE}
writeLines(readLines("_song2017how-table-s1.md"))
```

To make it easier to produce these tallies, I'll reformat the `lag`
data frame.

```{r lag_tally, dependson = "lag"}
reformat_lag <- function(data){
    separate(data, .data$matchup,
             sep = "@", into = c("away_team", "home_team"),
             remove = FALSE) %>%
        mutate(field = factor(ifelse(.data$team == .data$home_team,
                                     "home",
                                     "away"),
                              levels = c("home", "away")),
               direction = factor(case_when(.data$lag > 0 ~ "to_east",
                                            .data$lag < 0 ~ "to_west",
                                            TRUE ~ "none"),
                                  levels = c("none", "to_west", "to_east"))) %>%
        select(date, team, field, direction, everything()) %>%
        select(-home_team, -away_team)
}

lag_tally <- reformat_lag(lag)
```

First, let's focus on the "West" and "East" rows of Table S1.

```{r, dependson = "lag_tally"}
lag_tally %>%
    count(field, direction) %>%
    spread(field, n)
```

Those tallies are similar enough that I don't think my lag
calculations are entirely off base.  If I generate the lag values
using the time zone of the home team rather the time zone of the park,
I can get closer to the Table S1 tallies.

```{r lag_ht, cache.extra = file.info("../lag/lag-combined-1992_2011-ht.csv")}
lag_ht <- read_csv("../lag/lag-combined-1992_2011-ht.csv") %>%
    mutate(date = ymd(date),
           year = year(date),
           game_tz = factor(game_tz,
                            levels = c("ET", "CT", "MT", "PT", "other")))
```

```{r lag_ht_tally, dependson = c("lag_tally", "lag_ht")}
lag_ht_tally <- reformat_lag(lag_ht)
```

```{r, dependson = "lag_ht_tally"}
lag_ht_tally %>%
    count(field, direction) %>%
    spread(field, n)
```

Each count from my generated data set is within three of the
corresponding reported value.  When these lags are split up by their
magnitude, the counts for these groups are also close if not identical
to what's reported in Table S1.

```{r, dependson = "lag_ht_tally"}
lag_ht_tally %>%
    filter(direction != "none") %>%
    count(field, direction, abs(lag)) %>%
    spread(field, n)
```

So it seems that (1) I'm calculating my lags in a way that's similar
to SSA's jet lag definition and (2) SSA based their time zone based on
the recorded home team rather than the time zone of the park's
location.  These usually but not always line up:

```{r, dependson = c("lag_tally")}
odd_parks <- filter(lag_tally, field == "home") %>%
    ## Group parks for same team (e.g., ARL01, ARL02).
    mutate(park_prefix = substring(park, 1, 3)) %>%
    select(team, park_prefix) %>%
    distinct() %>%
    count(team) %>%
    filter(n > 1) %>%
    .$team

filter(lag_tally, team %in% odd_parks & field == "home") %>%
    select(team, park) %>%
    arrange(team, park) %>%
    distinct() %>%
    as.data.frame()
```

Within this list, we can see games played in Disney's Wide World of
Sports Complex, Hawaii, Japan, Puerto Rico, and Mexico.  There are
also games at a usual MLB park where the home team doesn't match.  For
example, the Marlins played as the home team in
Seattle [because of a U2 concert][u2].

[u2]: https://www.baseball-reference.com/boxes/SEA/SEA201106260.shtml

### SSA's Table S2

I'll need to do a little more work to compare my lag data set with
SSA's Table S2. With the help of pandoc, I've converted their docx
table into a more useful format.

```{r s2_wide, cache.extra = file.info("../lag/song2017how-table-s2.csv")}
(s2_wide <- read_csv("../lag/song2017how-table-s2.csv") %>%
    mutate(date = ymd(date)))
```

Notice that there are many fewer rows in this data frame than in
`lag`, which has `r formatC(nrow(lag), format = "d", big.mark = ",")`
rows.  One reason for this is because now each team of a game is
represented on the same line.  Another reason is that `s2_wide` only
includes games where at least one team had a lag magnitude at or above
two.

```{r, dependson = "s2_wide"}
s2_wide %>%
    filter(abs(away_lag) < 2 & abs(home_lag) < 2)
```

I want to compare the two data sets with a join, so I need to bring
their representations a bit closer.  `s2_wide` doesn't include double
header information, so we can't form a unique row key.  Instead, I'll
filter out double header rows from both data sets.  (This shouldn't
matter because the lags shouldn't change across two games on the same
day.)

```{r s2_cmp, dependson = "s2_wide"}
(s2_cmp <- s2_wide %>%
    mutate(matchup = paste0(away, "@", home)) %>%
    gather(key = "type_team", value = "team", away, home) %>%
    gather(key = "type_lag", value = "lag", away_lag, home_lag) %>%
    arrange(date, matchup) %>%
    mutate(type_lag = str_replace(type_lag, "_lag", "")) %>%
    filter(type_team == type_lag) %>%
    select(date, team, lag, matchup))
```

```{r lag_cmp, dependson = "lag"}
prepare_cmp <- function(data){
    filter(data, .data$game_id < 2) %>%
        mutate(team = case_when(.data$team == "CAL" ~ "ANA",
                                .data$team == "MON" ~ "WAS",
                                TRUE ~ .data$team),
               matchup = str_replace(.data$matchup, "CAL", "ANA"),
               matchup = str_replace(matchup, "MON", "WAS"))
}

lag_cmp <- prepare_cmp(lag)
lag_ht_cmp <- prepare_cmp(lag_ht)
```

Now the two tables can be joined (well, three tables because I'm using
both the park-based and home-team-based lag values).

```{r full, dependson = c("lag_cmp", "s2_cmp")}
full <- full_join(lag_cmp, s2_cmp,
              suffix = c("", ".s2"),
              by = c("date" = "date",
                     "team" = "team",
                     "matchup" = "matchup"))

full_ht <- full_join(lag_ht_cmp, s2_cmp,
                     suffix = c("", ".s2"),
                     by = c("date" = "date",
                            "team" = "team",
                            "matchup" = "matchup"))
```
All the games in Table S2 appear to be in my generated tables.

```{r, dependson = "full"}
filter(full, is.na(lag))
filter(full_ht, is.na(lag))
```

A few of the lag values don't match up for the home-team-based lag
values.

```{r, dependson = "full"}
filter(full_ht, lag != lag.s2) %>%
    select(-game_id, -year)
```

Looking at the game logs as well as baseball-reference.com, my values
seem right, so that probably indicates that I'm missing a few edge
cases of the lag calculation rules.  One edge case that I think
explains the first three of these is calculating the lag for a trip
when the team starts off with a lag.  For example, for the April 18,
2007, entry above, San Diego had a +1 lag when it [traveled][sdn] from
Chicago back to San Diego, so they ended up at -1 in my calculations
instead of -2.  I'm not sure what makes the most sense here, but these
events are pretty rare because a team usually stays around for at last
three days, which is enough to drop their lag back to zero.

For most of the entries, though, I'm not spotting any obvious
explanations.

[sdn]: https://www.baseball-reference.com/teams/SDP/2007-schedule-scores.shtml

When I consider the park-based lags instead, there are of course
additional discrepancies.

```{r, dependson = "full"}
filter(full, lag != lag.s2) %>%
    select(-game_id, -year) %>%
    as.data.frame()
```

On the other hand, when I subset my generated data set based on Table
S2's criteria, I find eight rows (four games) that aren't in Table S2
if I use the home-team-based values.

```{r, dependson = "full"}
full_ht %>%
    filter(is.na(lag.s2)) %>%
    group_by(date, matchup, game_id) %>%
    filter(max(abs(lag)) > 1) %>%
    ungroup() %>%
    select(-lag.s2, -game_id) %>%
    as.data.frame()
```

The two ATL&#64;SEA games are the result of the U2 situation described
above (which was the Mariner's previous series).  My guess is that,
instead of using the park IDs to get the time zone, SSA are flagging
these series as problematic and filtering them out.

Here are the parked-based values that aren't in Table S2:

```{r, dependson = "full"}
full %>%
    filter(is.na(lag.s2)) %>%
    group_by(date, matchup, game_id) %>%
    filter(max(abs(lag)) > 1) %>%
    ungroup() %>%
    select(-lag.s2, -game_id) %>%
    as.data.frame()
```

So, based on the comparisons with Table S1 and S2, I think

  * my lag calculations pretty closely follow SSA's definition
    because, using the home-team-based time zones, there is good,
    though not perfect, agreement between the sets.

  * SSA didn't use the park ID to determine the time zone.

I will use my park-based lag calculations going forward.

------------------------------------------------------------------------

```{r session_info, echo = FALSE, results = "asis"}
source("session-info.R")
```
